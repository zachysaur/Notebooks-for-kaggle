{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working\n!git clone -b totoro3 https://github.com/camenduru/ComfyUI /kaggle/working/TotoroUI\n%cd /kaggle/working/TotoroUI\n\n!pip install -q torchsde einops diffusers accelerate xformers==0.0.23.post1\n!apt -y install -qq aria2\n\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8.safetensors -d /kaggle/working/TotoroUI/models/unet -o flux1-dev-fp8.safetensors\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /kaggle/working/TotoroUI/models/vae -o ae.sft\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /kaggle/working/TotoroUI/models/clip -o clip_l.safetensors\n!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /kaggle/working/TotoroUI/models/clip -o t5xxl_fp8_e4m3fn.safetensors\n\nimport random\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport nodes\nfrom nodes import NODE_CLASS_MAPPINGS\nfrom totoro_extras import nodes_custom_sampler\nfrom totoro import model_management\n\nDualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\nUNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\nRandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\nBasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\nKSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\nBasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\nSamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\nVAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\nVAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\nEmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n\nwith torch.inference_mode():\n    clip = DualCLIPLoader.load_clip(\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0]\n    unet = UNETLoader.load_unet(\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\")[0]\n    vae = VAELoader.load_vae(\"ae.sft\")[0]\n\ndef closestNumber(n, m):\n    q = int(n / m)\n    n1 = m * q\n    if (n * m) > 0:\n        n2 = m * (q + 1)\n    else:\n        n2 = m * (q - 1)\n    if abs(n - n1) < abs(n - n2):\n        return n1\n    return n2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.idle":"2024-08-03T00:50:38.191682Z","shell.execute_reply.started":"2024-08-03T00:47:38.315215Z","shell.execute_reply":"2024-08-03T00:50:38.190606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.inference_mode():\n    positive_prompt = \"black forest toast spelling out the words 'FLUX DEV', tasty, food photography, dynamic shot\"\n    width = 1024\n    height = 1024\n    seed = 0\n    steps = 20\n    sampler_name = \"euler\"\n    scheduler = \"simple\"\n\n    if seed == 0:\n        seed = random.randint(0, 18446744073709551615)\n    print(seed)\n\n    cond, pooled = clip.encode_from_tokens(clip.tokenize(positive_prompt), return_pooled=True)\n    cond = [[cond, {\"pooled_output\": pooled}]]\n    noise = RandomNoise.get_noise(seed)[0] \n    guider = BasicGuider.get_guider(unet, cond)[0]\n    sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n    sigmas = BasicScheduler.get_sigmas(unet, scheduler, steps, 1.0)[0]\n    latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n    sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n    model_management.soft_empty_cache()\n    decoded = VAEDecode.decode(vae, sample)[0].detach()\n    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(\"/kaggle/working/flux.png\")\n\nImage.fromarray(np.array(decoded*255, dtype=np.uint8)[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T00:50:38.193421Z","iopub.execute_input":"2024-08-03T00:50:38.193797Z"},"trusted":true},"execution_count":null,"outputs":[]}]}