{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6898670,"sourceType":"datasetVersion","datasetId":3954404},{"sourceId":6925544,"sourceType":"datasetVersion","datasetId":3953428}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{"id":"G9BdiCppV6AS"}},{"cell_type":"markdown","source":"Installing & preparing requirements","metadata":{"id":"0ZYRNb0AWLLW"}},{"cell_type":"markdown","source":"# Installation ","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\nimport torch\nimport codecs\n\nif torch.cuda.is_available():\n    !apt-get update\n    !apt-get install -y nvidia-cuda-toolkit\n    device = \"cuda\"\n    print(\"Using GPU\")\nelse:\n    device = \"cpu\"\n    print(\"Using CPU\")\n\ngit_repo_rot13 = 'uggcf://tvguho.pbz/P0hagSyblq/ebbc-hayrnfurq.tvg'\ngit_repo = codecs.decode(git_repo_rot13, 'rot 13')\n\ndirectory_rot13 = 'ebbc-hayrnfurq'\ndirectory = codecs.decode(directory_rot13, 'rot 13')\n\n# Clone the repository\n!git clone $git_repo /kaggle/working/$directory\n\n# Change directory to the cloned repository\n%cd /kaggle/working/$directory\n\n# Install requirements if they exist\n!pip install -r requirements.txt\n\n# Install additional package\n!pip install onnxruntime-gpu\n","metadata":{"id":"t1yPuhdySqCq","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall Gradio -y\n!pip install gradio==4.32.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Launch with Pinggy","metadata":{}},{"cell_type":"code","source":"from multiprocessing import Process\nimport sys\nimport time\nimport codecs\n\n# Ensure the log file exists and is empty\n!touch log.txt\nopen('log.txt', 'w').close()\n\ndef run_app():\n    directory_rot13 = 'ebbc-hayrnfurq'\n    directory = codecs.decode(directory_rot13, 'rot 13')\n    cmd = f\"python /kaggle/working/{directory}/run.py & ssh -o StrictHostKeyChecking=no -p 80 -R 0:localhost:7860 a.pinggy.io > log.txt\"\n    get_ipython().system(cmd)\n    \ndef print_url():\n    print(\"waiting for output\")\n    time.sleep(2)\n    sys.stdout.flush()\n    \n    found = False\n    while not found:\n        with open('log.txt', 'r') as file:\n            end_word = '.pinggy.io'\n            for line in file:\n                start_index = line.find(\"http://\")\n                if start_index != -1:\n                    end_index = line.find(end_word, start_index)\n                    if end_index != -1:\n                        print(\"游때 游때 游때\")\n                        print(\"URL: \" + line[start_index:end_index + len(end_word)])\n                        print(\"游때 游때 游때\")\n                        found = True\n                        break\n        if not found:\n            time.sleep(2)  # Sleep before checking again\n\np_app = Process(target=run_app)\np_url = Process(target=print_url)\np_app.start()\np_url.start()\np_app.join()\np_url.join()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Running roop-unleashed with default config","metadata":{"id":"u_4JQiSlV9Fi"}},{"cell_type":"markdown","source":"# FFmpeg","metadata":{}},{"cell_type":"code","source":"!apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}